#!/bin/bash
#
# Copy the published LongView files passed in as $1 to a unique winc name then insert it
#  into the LDM queue.  This is for the Seasonal and Subseasonal files
#  coming from LongView and heading for the CPG.
#
##########################################################################################
PATH=/usr/local/bin:/bin:$PATH
export PATH

umask 0000
_LOGFILE=/longview/logs/published_file.
DATE=`date -u "+%Y%m%dT%H%M%S"`

# Directory in which to find the files
SRC_DIR="/longview/Pub"
DEST_DIR="/longview/Pub/out"

###echo "Operating on $1"

# Sample input file names from LongView publisher
#   Subseasonal (weekly) temperatures (for North America and Europe)
# subseasonal_Tc_Week3_20180914.txt
# subseasonal_Tc_Week4_20180914.txt
# subseasonal_Tc_Week5_20180914.txt
#   Seasonal rollup temperature and precip anomalies for global
# sea13_precip_primary_fcst_global30.txt
# sea24_precip_primary_fcst_global30.txt
# sea35_precip_primary_fcst_global30.txt
# sea13_temp_primary_fcst_global10.txt
# sea24_temp_primary_fcst_global10.txt
# sea35_temp_primary_fcst_global10.txt
# sea13_temp_primary_fcst_global30.txt
# sea24_temp_primary_fcst_global30.txt
# sea35_temp_primary_fcst_global30.txt
#   Seasonal temperatures and precip anomalies for global
# month1_temp_primary_fcst_global30.txt
# month2_temp_primary_fcst_global30.txt
# month3_temp_primary_fcst_global30.txt
# month4_temp_primary_fcst_global30.txt
# month1_temp_primary_fcst_global10.txt
# month2_temp_primary_fcst_global10.txt
# month3_temp_primary_fcst_global10.txt
# month4_temp_primary_fcst_global10.txt
# month1_precip_primary_fcst_global30.txt
# month2_precip_primary_fcst_global30.txt
# month3_precip_primary_fcst_global30.txt
# month4_precip_primary_fcst_global30.txt
#
#   The WINC names are divided into 9 fields. See https://docs.google.com/document/d/1beYoLzCgjYvE8pegltpzNPk1XCiZlYf_YOMjZrabZqQ/edit#
#   for details.
#
# Initialize things with nonsense values
seasonal="nope"
rollup="nuhuh"
first="last"
forecast_type="best"

echo "$0 processing file         $1" | /usr/local/bin/datelogin ${_LOGFILE}
# Decompose the filename passed in
#     Get the forecast type to indentify which of the three types it contains 
#     (Seasonal ^month, Subseasonal ^subseasonal, Rollup ^sea)
first=`echo $1 | cut -c 1-3`
###echo "first is $first"

if [ "$first" = "sub" ]
then
    #  Set the flags to values to represent the data type as subseasonal
    #
###    echo "  found subseasonal"
    forecast_type="wsi_subseasonal"
    seasonal="false"
    rollup="false"
elif [ "$first" = "mon" ]
then
    #  Set the flags to values to represent the data type as seasonal
    #
###    echo "  found monthly"
    forecast_type="wsi_seasonal"
    seasonal="true"
    rollup="false"
elif [ "$first" = "sea" ]
then
    #  Set the flags to values to represent the data type as rollup
    #
###    echo "  found rollup"
    forecast_type="wsi_seasonal"
    seasonal="false"
    rollup="true"
else
    #  Set the flags to values to represent the data type as unexpected
    #
    echo "  do not know what was found"
    forecast_type="unknown"
    seasonal="false"
    rollup="false"
fi

# Set the fields of the new file name (see Longview Published Files to WINC Name Pattern for more info)

# Field 1 - TYPE
#    This is always set to "rec" for all file types
#
TYPE="rec"
###echo "TYPE is $TYPE"

# Field 2 - SOURCE
#    This contains either "wsi_seasonal" (for monthly and rollups) or "wsi_subseasonal" (for the weekly forecasts)
#
SOURCE=$forecast_type
###echo "SOURCE is $SOURCE"

# Field 3 - VALID
#    This is a DateTtime string that refers to the start of the forecast data.
#    The  --date="string description" feature on the 'date' command is very useful here.
#    Be sure to use UTC time.
#
#  Initialize the VALID field to 00z today. Change it as needed for the different types and periods.
VALID=`date -u +%Y%m%dT000000Z`

if [ $seasonal = "false" ]
then
    if [ $rollup = "true" ]
    then
###        echo "Do the rollup things"
        rollnum=`echo $1 |awk -F_ '{print $1}' | cut -c 4`
###        echo "rollnum is $rollnum"
        #        UTC           First-of-month  Number time-period                  
        VALID=`date -u --date="$(date +%Y%m01) $rollnum month" +%Y%m%dT000000Z`
    else
        week=`echo $1 | awk -F_ '{print $3}' | cut -c 5`
        VALID=`date -u --date="$week Monday" +%Y%m%dT000000Z`
    fi
elif [ $rollup = "false" ]
then
    monthnum=`echo $1 |awk -F_ '{print $1}' | cut -c 6`
    VALID=`date -u --date="$(date +%Y%m01) $monthnum month" +%Y%m%dT000000Z`
fi
###echo "VALID is $VALID"

# Field 4 - PUBTIME
#    This is "now", the time the file is created and inserted into LDM.
#
PUBTIME=`date -u +%Y%m%dT%H%M%SZ`
###echo "PUBTIME is $PUBTIME"

# Field 5 - PERIOD_END
#    This represents the number of days covered by the forecast period and the start
#    of the first day of the forecast. Lots of other special rules based on forecast
#    type. See the doc for details.
#
# Initialize it to a value that will be overwritten.
DD="00"
if [ $seasonal = "true" ]
then
###    echo "is seasonal"
    monthnum=`echo $1 |awk -F_ '{print $1}' | cut -c 6`
    DD="$(expr $monthnum \* 30 )"

elif [ $rollup = "true" ]
then
###    echo "Is a rollup"
    rollnum=`echo $1 |awk -F_ '{print $1}' | cut -c 4`
    DD="$(expr $rollnum \* 30 )"

else # must be a subseasonal file
    week=`echo $1 | awk -F_ '{print $3}' | cut -c 5`
    #  Get the epoch time of the correct Monday and subtract the epoch time of today.
    #  Divide by 86400 (seconds per day)
    #target_monday=`date -u --date="$week Monday" +%s`
    #today=`date -u --date="00z today" +%s`
    #seconds=$(expr $target_monday - $today) 
    #DD="$(expr $seconds / 86400)"
    DD="$(expr $week \* 7 )"
##    echo "$0 DD is $DD" | /usr/local/bin/datelogin ${_LOGFILE}
fi
PERIOD_END="P${DD}DT00H00M"
###echo "PERIOD_END is $PERIOD_END"

# Field 6 - REGION
#    Turns out that all types are global. Commented out the logic for subseasonal.
#
#if [ $forecast_type = "wsi_seasonal" ]
#then
#    REGION="GLOBAL"
####    echo "seasonal implies GLOBAL"
#else
#    # NA sites are published on Tuesdays. EUR sites on Wednesdays.
#    DOW=`date -u +%a`
#    if [ $DOW = "Tue" ]
#    then
#        REGION="NA"
####        echo "Tuesday implies North America"
#    elif [ $DOW = "Wed" ]
#    then
#        REGION="EUR"
#        echo "Wednesday implies Europe"
#    else
#        REGION="ZZZ"
#        echo "unknown region"
#    fi
#fi
REGION="GLOBAL"
###echo "REGION is $REGION"

# Field 7 - PARAM_LEN
#    This is a combination of the parameter name and the forecast period length.
#
#    Initialize to subseasonal (weekly) and change for seasonal and rollups as needed.
LEN="P7D"
param="TANOM"
CLIMO="30"
#    The subseasonal files do not follow this pattern, but at the moment they are all 30-yr climo.
if [[ ($seasonal = "true") || ($rollup = "true") ]]
then
    CLIMO=`echo $1 | awk -F_ '{print $NF}' | cut -c 7-8`
fi
echo "Climo is $CLIMO"
 
if [ $seasonal = "true" ]
then
    LEN="P1M"
###    echo "seasonal implies one month"
    param_name=`echo $1 | awk -F_ '{print $2}'`
    if [ $param_name = "precip" ]
    then
        param="PANOM"
    elif [ $param_name = "prcp" ]
    then
        echo "found prcp"
        param="PANOM"
    fi
fi
if [ $rollup = "true" ]
then
    LEN="P3M"
###    echo "rollup implies three months"
    param_name=`echo $1 | awk -F_ '{print $2}'`
    if [ $param_name = "precip" ]
    then
        echo "found precip"
        param="PANOM"
    elif [ $param_name = "prcp" ]
    then
        echo "found prcp"
        param="PANOM"
    fi
fi 
    
PARAM_LEN="${param}${CLIMO}@${LEN}"
echo "PARAM_LEN is $PARAM_LEN"

# Field 8 - LEVEL
#    This is always set to surface (SFC) because this data is never on other atmosphere levels.
#
LEVEL="SFC"
###echo "LEVEL is $LEVEL"

# Field 9 - EXT
#    This indicates the type of data contained within. This is location-value data, so simple text.
#
EXT="txt"
echo "EXT is $EXT"

# Build the new file name
NEW_FILE=$TYPE.$SOURCE.$VALID.$PUBTIME.$PERIOD_END.$REGION.$PARAM_LEN.$LEVEL.$EXT

echo "$1       turns into  "
echo $NEW_FILE

# Create the 30yr monthly files for North America so they can be turned into departures from 10yr climo.
if [[ $seasonal == "true" && $rollup == "false" ]]
then
    echo "Make $1 into a NorthAmerica monthly file"
    /usr/local/bin/filter_NA_sites ${SRC_DIR}/${1} >> ${DEST_DIR}/month${monthnum}_NA_30yr_TANOM.txt
fi

# Quit out early when debugging
###exit 0

#--------------------------
# Use mv in operations to allow new files to be written without conflict.
mv ${SRC_DIR}/$1 ${DEST_DIR}/$NEW_FILE
chmod ug+w ${DEST_DIR}/$NEW_FILE

if [ -e "${SRC_DIR}/$1" ]
then
        echo "${SRC_DIR}/$1 did not get removed. Force it." | /usr/local/bin/datelogin ${_LOGFILE}
        rm -f ${SRC_DIR}/$1
fi

# Insert the file into the LDM queue if and only if you are running on the Live Primary system
if [ `/usr/local/bin/is_primary` -ne 0 ]
then
    echo "$0 ---- not primary ---- No insert to LDM queue ($NEW_FILE)." | /usr/local/bin/datelogin ${_LOGFILE}
    exit 0
fi

# Insert the file into the LDM queue.
RET="`/opt/ldm/bin/pqinsert -v -l - -i -f WSI -p $NEW_FILE $DEST_DIR/$NEW_FILE 2>&1`"
RETVAL=$?
if [ $RETVAL -eq 0 ]
then
    echo "$0 : SUCCESSFUL insertion to LDM : $NEW_FILE" | /usr/local/bin/datelogin ${_LOGFILE}
    # Send the SIGCONT to alert listeners to the arrival of the data immediately
    LDMD_PID=`cat ~ldm/ldmd.pid`
    kill -s CONT -$LDMD_PID
else
    (
	echo
	echo "$0"
	echo "    FAILED to insert $DEST_DIR/$NEW_FILE to LDM."
	echo "      Return Value: $RETVAL"
	echo "      $RET"
    ) | /usr/local/bin/datelogin ${_LOGFILE}

fi

exit 0
